{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10818874,"sourceType":"datasetVersion","datasetId":6717276},{"sourceId":10820204,"sourceType":"datasetVersion","datasetId":6717986}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install polars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:29:43.323850Z","iopub.execute_input":"2025-02-22T17:29:43.324150Z","iopub.status.idle":"2025-02-22T17:29:47.995664Z","shell.execute_reply.started":"2025-02-22T17:29:43.324119Z","shell.execute_reply":"2025-02-22T17:29:47.994554Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (1.9.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport ast\nimport numpy as np\nfrom transformers import BertModel, BertConfig\nfrom sklearn.model_selection import train_test_split\nimport polars as pl\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:58:29.679716Z","iopub.execute_input":"2025-02-24T04:58:29.679974Z","iopub.status.idle":"2025-02-24T04:58:50.493346Z","shell.execute_reply.started":"2025-02-24T04:58:29.679944Z","shell.execute_reply":"2025-02-24T04:58:50.492422Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pl.read_parquet('/kaggle/input/cxc-2025-rnn-data/rnn_data.parquet')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:58:54.815558Z","iopub.execute_input":"2025-02-24T04:58:54.815879Z","iopub.status.idle":"2025-02-24T04:58:55.184327Z","shell.execute_reply.started":"2025-02-24T04:58:54.815851Z","shell.execute_reply":"2025-02-24T04:58:55.183463Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"shape: (5, 4)\n┌─────────────────────────────────┬───────────────┬────────────────────────┬────────┐\n│ user_id                         ┆ session_id    ┆ event_type_mapped_list ┆ target │\n│ ---                             ┆ ---           ┆ ---                    ┆ ---    │\n│ str                             ┆ str           ┆ list[i64]              ┆ i64    │\n╞═════════════════════════════════╪═══════════════╪════════════════════════╪════════╡\n│ afe99d2f-4fce-4584-a360-967b87… ┆ 1715551789566 ┆ [553]                  ┆ 634    │\n│ de762acc-c1cd-4308-8e5e-80ba1d… ┆ 1721053697224 ┆ [349]                  ┆ 531    │\n│ 6ddede71-f391-48ba-9d87-32cf6b… ┆ 1730825985104 ┆ [349]                  ┆ 238    │\n│ 6ddede71-f391-48ba-9d87-32cf6b… ┆ 1730825985104 ┆ [349, 238]             ┆ 691    │\n│ 6ddede71-f391-48ba-9d87-32cf6b… ┆ 1730825985104 ┆ [349, 238, 691]        ┆ 490    │\n└─────────────────────────────────┴───────────────┴────────────────────────┴────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>session_id</th><th>event_type_mapped_list</th><th>target</th></tr><tr><td>str</td><td>str</td><td>list[i64]</td><td>i64</td></tr></thead><tbody><tr><td>&quot;afe99d2f-4fce-4584-a360-967b87…</td><td>&quot;1715551789566&quot;</td><td>[553]</td><td>634</td></tr><tr><td>&quot;de762acc-c1cd-4308-8e5e-80ba1d…</td><td>&quot;1721053697224&quot;</td><td>[349]</td><td>531</td></tr><tr><td>&quot;6ddede71-f391-48ba-9d87-32cf6b…</td><td>&quot;1730825985104&quot;</td><td>[349]</td><td>238</td></tr><tr><td>&quot;6ddede71-f391-48ba-9d87-32cf6b…</td><td>&quot;1730825985104&quot;</td><td>[349, 238]</td><td>691</td></tr><tr><td>&quot;6ddede71-f391-48ba-9d87-32cf6b…</td><td>&quot;1730825985104&quot;</td><td>[349, 238, 691]</td><td>490</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"with open('/kaggle/input/cxc-2025-rnn-data/idx_to_event.pkl', 'rb') as f:\n    idx_to_event = pickle.load(f, encoding='latin1')\n\n# Convert Polars columns to Python lists for compatibility with the dataset (potientially use for different)\nsequences = df[\"event_type_mapped_list\"].to_list()  # Converts to list of lists\ntargets = df[\"target\"].to_list()  # Converts to list of integers\n\n# Define hyperparameters\nnum_items = len(idx_to_event) + 1\nhidden_size = 128\nnum_layers = 2\nnum_heads = 2\nmax_seq_len = 10  # Adjusted for longer sequences if needed\nlearning_rate = 1e-4\nbatch_size = 32\nnum_epochs = 50\n\n# Define the dataset class\nclass BERT4RecDataset(Dataset):\n    def __init__(self, df, max_seq_len=3):\n        self.sequences = df[\"event_type_mapped_list\"].to_list()\n        self.targets = df[\"target\"].to_list()\n        self.max_seq_len = max_seq_len\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        seq = self.sequences[idx]      # e.g. [10, 22]\n        target = self.targets[idx]     # e.g. 15\n\n        # 1) Convert to list if not already\n        if not isinstance(seq, list):\n            seq = []\n\n        # 2) Pad or truncate to length = max_seq_len\n        seq_len = len(seq)\n        if seq_len < self.max_seq_len:\n            seq = [740] * (self.max_seq_len - seq_len) + seq\n        else:\n            seq = seq[-self.max_seq_len:]\n\n        # 3) Convert to tensors\n        input_seq = torch.tensor(seq, dtype=torch.long)       # shape: (max_seq_len,)\n        target_action = torch.tensor(target, dtype=torch.long) # shape: ()\n\n        # 4) Return\n        return input_seq, target_action\n\n# Define the BERT4Rec model\nclass BERT4Rec(nn.Module):\n    def __init__(self, num_items, hidden_size, num_layers, num_heads, max_seq_len):\n        super(BERT4Rec, self).__init__()\n        \n        self.config = BertConfig(\n            vocab_size=num_items,\n            hidden_size=hidden_size,\n            num_hidden_layers=num_layers,\n            num_attention_heads=num_heads,\n            intermediate_size=hidden_size * 4,\n            max_position_embeddings=max_seq_len,\n            pad_token_id=740\n        )\n        \n        self.bert = BertModel(self.config)\n        self.fc = nn.Linear(hidden_size, num_items)\n\n    def forward(self, input_ids):\n        attention_mask = (input_ids != 0).long()\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs.last_hidden_state\n        last_token_hidden = last_hidden_state[:, -1, :]  # (batch_size, hidden_size)\n        logits = self.fc(last_token_hidden)              # (batch_size, num_items)\n        return logits\n\ndf = df.filter(\n    pl.col('user_id') != 'EMPTY'\n).with_columns(\n    pl.col('user_id').map_elements(lambda x: x[-1], return_dtype=pl.String).alias('train')\n)\n\ntrain_df = df\ntest_df = df.filter(\n    (pl.col('train') == 'e') | (pl.col('train') == '6')\n)\n\nval_df = df.filter(\n    (pl.col('train') == 'f') | (pl.col('train') == '9')\n)\n\n# Create datasets\ntrain_dataset = BERT4RecDataset(train_df, max_seq_len)\nval_dataset = BERT4RecDataset(val_df, max_seq_len)\ntest_dataset = BERT4RecDataset(test_df, max_seq_len)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Create model, optimizer, etc.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = BERT4Rec(num_items, hidden_size, num_layers, num_heads, max_seq_len).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n\n# Training Loop\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0.0\n    \n    for input_seq, target_action in train_loader:\n        input_seq = input_seq.to(device)\n        target_action = target_action.to(device)\n\n        optimizer.zero_grad()\n        logits = model(input_seq)                 # (batch_size, num_items)\n        loss = criterion(logits, target_action)    # raw logits + CrossEntropyLoss\n        loss.backward()\n        optimizer.step()\n        total_train_loss += loss.item()\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n\n    # Validation Loop\n    model.eval()\n    total_val_loss = 0.0\n\n    with torch.no_grad():\n        for input_seq, target_action in val_loader:\n            input_seq = input_seq.to(device)\n            target_action = target_action.to(device)\n\n            logits = model(input_seq)\n            loss = criterion(logits, target_action)\n            total_val_loss += loss.item()\n\n    avg_val_loss = total_val_loss / len(val_loader)\n    print(f\"[Epoch {epoch+1}/{num_epochs}] \"\n          f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n# Test Loop\nmodel.eval()\ntotal_test_loss = 0.0\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for input_seq, target_action in test_loader:\n        input_seq = input_seq.to(device)\n        target_action = target_action.to(device)\n\n        logits = model(input_seq)\n        loss = criterion(logits, target_action)\n        total_test_loss += loss.item()\n\n        # Calculate accuracy\n        _, predicted = torch.max(logits, 1)\n        correct += (predicted == target_action).sum().item()\n        total += target_action.size(0)\n\navg_test_loss = total_test_loss / len(test_loader)\naccuracy = correct / total\nprint(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:29:47.996753Z","iopub.execute_input":"2025-02-22T17:29:47.997079Z","iopub.status.idle":"2025-02-22T19:44:01.148704Z","shell.execute_reply.started":"2025-02-22T17:29:47.997053Z","shell.execute_reply":"2025-02-22T19:44:01.147895Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1/20] Train Loss: 1.1087, Val Loss: 1.0224\n[Epoch 2/20] Train Loss: 0.9848, Val Loss: 0.9857\n[Epoch 3/20] Train Loss: 0.9585, Val Loss: 0.9679\n[Epoch 4/20] Train Loss: 0.9442, Val Loss: 0.9563\n[Epoch 5/20] Train Loss: 0.9346, Val Loss: 0.9502\n[Epoch 6/20] Train Loss: 0.9275, Val Loss: 0.9422\n[Epoch 7/20] Train Loss: 0.9223, Val Loss: 0.9383\n[Epoch 8/20] Train Loss: 0.9185, Val Loss: 0.9380\n[Epoch 9/20] Train Loss: 0.9149, Val Loss: 0.9311\n[Epoch 10/20] Train Loss: 0.9123, Val Loss: 0.9308\n[Epoch 11/20] Train Loss: 0.9099, Val Loss: 0.9276\n[Epoch 12/20] Train Loss: 0.9079, Val Loss: 0.9266\n[Epoch 13/20] Train Loss: 0.9062, Val Loss: 0.9233\n[Epoch 14/20] Train Loss: 0.9045, Val Loss: 0.9263\n[Epoch 15/20] Train Loss: 0.9033, Val Loss: 0.9194\n[Epoch 16/20] Train Loss: 0.9023, Val Loss: 0.9262\n[Epoch 17/20] Train Loss: 0.9007, Val Loss: 0.9238\n[Epoch 18/20] Train Loss: 0.9000, Val Loss: 0.9202\n[Epoch 19/20] Train Loss: 0.8989, Val Loss: 0.9176\n[Epoch 20/20] Train Loss: 0.8983, Val Loss: 0.9171\nTest Loss: 0.9859, Test Accuracy: 0.7141\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def recommend_next_action(user_sequence):\n    \"\"\"Predict next-action probabilities for a given user sequence,\n       then return top-k predictions and their probabilities.\"\"\"\n    model.eval()\n    with torch.no_grad():\n        # Convert user_sequence to a batched tensor of shape (1, max_seq_len)\n        seq_len = len(user_sequence)\n        if seq_len < max_seq_len:\n            user_sequence = [0]*(max_seq_len - seq_len) + user_sequence\n        else:\n            user_sequence = user_sequence[-max_seq_len:]\n\n        input_seq = torch.tensor(user_sequence, dtype=torch.long).unsqueeze(0).to(device)\n        logits = model(input_seq)  # shape (1, num_items)\n\n        # Convert logits to probabilities\n        probabilities = torch.softmax(logits, dim=-1)  # shape (1, num_items)\n\n        # Top-k next items\n        top_k = 1\n        topk_values, topk_indices = torch.topk(probabilities, k=top_k, dim=-1)  # shape (1, k) each\n        topk_values = topk_values.squeeze(0).cpu().numpy()\n        topk_indices = topk_indices.squeeze(0).cpu().numpy()\n\n    return topk_indices, topk_values\n\nuser_seq = [1, 2]  # user has done events 1, then 2\npredicted_actions, probs = recommend_next_action(user_seq)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T19:50:16.178057Z","iopub.execute_input":"2025-02-22T19:50:16.178349Z","iopub.status.idle":"2025-02-22T19:50:16.187756Z","shell.execute_reply.started":"2025-02-22T19:50:16.178326Z","shell.execute_reply":"2025-02-22T19:50:16.187078Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"predicted_actions, probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T19:50:16.517386Z","iopub.execute_input":"2025-02-22T19:50:16.517661Z","iopub.status.idle":"2025-02-22T19:50:16.522659Z","shell.execute_reply.started":"2025-02-22T19:50:16.517639Z","shell.execute_reply":"2025-02-22T19:50:16.522016Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(array([460]), array([0.4038925], dtype=float32))"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"torch.save(model.state_dict(), \"bert4rec_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T19:44:01.208439Z","iopub.execute_input":"2025-02-22T19:44:01.208732Z","iopub.status.idle":"2025-02-22T19:44:01.230324Z","shell.execute_reply.started":"2025-02-22T19:44:01.208703Z","shell.execute_reply":"2025-02-22T19:44:01.229690Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"user_sequence = [1,2]\nseq_len = len(user_sequence)\nif seq_len < max_seq_len:\n    user_sequence = [0]*(max_seq_len - seq_len) + user_sequence\nelse:\n    user_sequence = user_sequence[-max_seq_len:]\ninput_seq = torch.tensor(user_sequence, dtype=torch.long).unsqueeze(0).to(device)\nlogits = model(input_seq)\nprobabilities = torch.softmax(logits, dim=-1)\nprobabilities_rounded = torch.round(probabilities * 100) / 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T19:51:24.279697Z","iopub.execute_input":"2025-02-22T19:51:24.280020Z","iopub.status.idle":"2025-02-22T19:51:24.287982Z","shell.execute_reply.started":"2025-02-22T19:51:24.279995Z","shell.execute_reply":"2025-02-22T19:51:24.287329Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"topk_values, topk_indices = torch.topk(probabilities_rounded, k=5, dim=-1)\ntopk_values, topk_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T19:52:01.507105Z","iopub.execute_input":"2025-02-22T19:52:01.507405Z","iopub.status.idle":"2025-02-22T19:52:01.514158Z","shell.execute_reply.started":"2025-02-22T19:52:01.507376Z","shell.execute_reply":"2025-02-22T19:52:01.513377Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(tensor([[0.4000, 0.2100, 0.0400, 0.0400, 0.0300]], device='cuda:0',\n        grad_fn=<TopkBackward0>),\n tensor([[460, 553,  20,  16, 607]], device='cuda:0'))"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"model_load = torch.load('/kaggle/working/bert4rec_model.pth', weights_only=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T20:02:40.888598Z","iopub.execute_input":"2025-02-22T20:02:40.888956Z","iopub.status.idle":"2025-02-22T20:02:40.901224Z","shell.execute_reply.started":"2025-02-22T20:02:40.888930Z","shell.execute_reply":"2025-02-22T20:02:40.900477Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"model(input_seq)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T20:02:04.651508Z","iopub.execute_input":"2025-02-22T20:02:04.651818Z","iopub.status.idle":"2025-02-22T20:02:04.673212Z","shell.execute_reply.started":"2025-02-22T20:02:04.651792Z","shell.execute_reply":"2025-02-22T20:02:04.672565Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([[ -7.1945,  -5.3142,  -6.6874, -13.1927,  -6.6779,  -2.8280,  -8.4970,\n         -13.1918,  -4.5702,  -5.2656, -13.1918,  -8.6398,  -0.7440,  -8.2066,\n         -13.1928,  -7.1815,   1.2277,  -4.4531, -12.5453, -13.1909,   1.2523,\n          -1.9722, -12.7996,  -4.5923,  -3.7978, -10.3480, -12.4543,  -4.2849,\n         -13.1918, -13.1919, -13.1914, -13.1923,  -4.4153, -12.6341,  -8.4430,\n          -6.8269,  -5.7460, -13.1912,  -4.6628, -13.1926, -10.9377, -13.1928,\n          -7.7358,  -3.3614, -13.1925,  -7.6509,  -7.0793,  -6.0046, -13.1913,\n         -13.1915,  -4.3490,  -3.4037,  -3.5399, -12.6127, -13.1927,  -0.0771,\n          -5.0143,  -6.6612,  -8.1107, -13.1916,  -8.8396, -13.1913, -13.1919,\n         -13.1925, -13.1921, -13.1922, -13.1918, -13.1909, -13.1917, -13.1922,\n         -13.1909, -13.1914, -13.1921, -13.1917, -11.9839, -13.1931,  -4.0807,\n          -4.7916,  -0.0411,  -2.6555,  -8.6739,  -5.7545, -13.1921,  -8.6077,\n         -10.2615, -13.1925, -13.1913, -11.9031,  -3.5294,  -4.3870, -12.4939,\n         -13.1918, -13.1932,  -5.8341,  -5.3039, -12.8208, -13.1924,  -4.2119,\n          -7.6564,  -7.9322,  -1.5533,  -7.0520,  -3.6265, -13.1918,  -4.6744,\n          -4.9513,  -4.1098,  -3.6287,  -4.8059, -13.1911, -10.7643,  -4.2463,\n          -5.3506,  -9.9588,  -8.4553, -13.1917,  -2.2640, -10.3025,  -4.0117,\n         -13.1924, -13.1924, -13.1927,  -6.9295, -13.1918,  -0.4527, -13.1924,\n         -12.2444,  -6.3775, -13.1916,  -5.3687,  -7.9652, -10.5434, -13.1926,\n         -10.9345,  -4.1951,  -4.0584,  -2.9122, -13.1923, -13.1916, -13.1927,\n         -12.7642, -13.1923, -13.1926, -13.1919, -12.8136,  -9.9313, -13.1915,\n          -3.4681, -13.1914, -13.1933, -10.5668, -13.1905, -13.1919, -13.1913,\n         -13.1914,  -2.6821,  -5.0600, -13.1934, -11.4732, -13.1910,  -3.4597,\n         -12.5281, -13.1919, -13.1918, -13.1931, -13.1927,  -4.9144,  -2.6251,\n         -13.1910,  -3.1800, -13.1918, -12.6496,  -3.0211,  -4.9192,  -3.4454,\n          -3.9440,  -5.0429, -13.1924, -13.1925, -12.6955,  -9.2416, -12.3667,\n         -13.1923,  -5.6411,  -3.6529,  -3.4822, -13.1922,  -6.9441, -10.8475,\n          -5.0504, -13.1908, -13.1918,  -6.0355, -13.1923,  -6.9719,  -9.7638,\n         -13.1929, -13.1915, -13.1922,  -5.7495, -10.5809,  -3.1020,  -2.6844,\n          -3.5878,  -3.8661,  -1.7646,  -1.9389,  -6.5681, -13.1924,  -7.2949,\n          -5.4564, -12.1251,  -9.9231,  -1.7504,  -6.9239,  -7.1030,  -7.8736,\n         -13.1916, -13.1908,  -3.4686, -13.1928,  -4.0652,  -3.6953, -11.3697,\n         -13.1927,  -7.2242,  -2.5908,  -0.4946, -10.1090, -13.1907, -13.1915,\n         -10.4061, -13.1921, -13.1912,  -7.4991, -13.1918,  -4.4763, -12.5493,\n          -2.3608,  -2.2669,  -0.4031,  -1.8889,  -0.1632,  -5.0813,  -5.6290,\n         -13.1929, -13.1923,  -4.9658, -13.1918, -13.1917, -12.7366,  -3.6471,\n          -4.4895, -12.8301, -13.1914,  -3.6556, -12.7864, -13.1912,  -4.7056,\n         -13.1928,  -3.1339,  -4.8748, -13.1925,  -4.3857,  -4.5829,  -6.9021,\n         -13.1922, -13.1924, -13.1940, -13.1916,  -6.5126,  -3.4706, -13.1919,\n          -4.8212, -13.1918,  -4.4685,  -1.5833,  -9.6998, -12.7783, -13.1921,\n         -13.1915, -13.1916, -12.5171, -13.1919, -10.7519, -10.9135, -13.1924,\n         -13.1924, -12.5316,  -4.5562,  -4.7445,  -5.7766, -13.1924,  -3.6121,\n          -4.6052,  -8.9490, -13.1913,  -9.5847,  -2.6326,  -3.7303, -12.8832,\n          -8.7608,  -6.3999,  -3.6288,  -4.4973,  -8.9538,  -9.4625, -10.5025,\n         -13.1916, -13.1921,  -4.5821, -13.1912, -11.8319, -13.1921,  -2.2493,\n          -5.3664, -13.1915,  -5.0946,  -2.1040,  -4.6998, -12.6528,  -0.8101,\n         -13.1921, -13.1928,  -4.7169,  -2.7973,  -1.9232,  -5.0223,  -5.7479,\n          -5.8210, -12.0672,  -4.1626,  -7.5975, -11.1569, -12.4422,  -0.5593,\n          -3.4250,  -4.2290,  -5.9857, -10.9064, -13.1922,  -5.2903,  -5.5386,\n         -13.1909, -13.1913, -13.1913, -13.1920,  -3.4154, -13.1910,  -2.8149,\n          -3.3502,  -5.1449,  -6.0030,  -3.8253,  -6.8673,  -3.0079, -13.1919,\n          -0.4476,  -6.1937,  -6.3880,  -5.8140,  -5.2116, -12.7385,  -8.6353,\n         -13.1916, -13.1920, -13.1916, -13.1910, -13.1924, -13.1923,  -3.1648,\n         -13.1921,  -3.9228,  -3.8500,  -9.4979,  -8.2000,  -4.7032,  -6.4124,\n         -13.1922,  -8.4596,  -2.0214, -13.1904,  -4.2732,  -3.8642,  -6.4767,\n          -4.9933, -11.2695,  -5.3880, -13.1932, -13.1915, -13.1918, -11.9618,\n          -1.2773, -12.7890,  -3.3963, -12.8971,  -1.2643,  -3.1706,  -3.3589,\n          -1.5469,  -6.6074, -11.6269,  -7.4633,  -7.6813,  -3.2999, -12.6426,\n          -2.5925,  -7.5251, -12.6569, -11.6653, -13.1926,  -4.2396, -13.1920,\n         -10.0930, -13.1925,  -3.7552, -13.1915,  -2.8365, -13.1919, -10.0750,\n          -0.3492,  -0.9533, -10.0605, -11.8582, -11.0092, -13.1918, -12.6454,\n          -4.7809, -10.0792,  -3.0604, -11.7197, -12.4008,  -7.2765,  -3.9233,\n          -4.4046, -13.1924,  -0.8282, -13.1933,  -9.4737,  -9.2283,  -0.8510,\n         -13.1914,  -2.4690,  -7.4146,   0.3174,  -4.4000,  -3.5991,  -4.4212,\n          -6.6042,  -4.2741, -13.1912, -10.6414,  -3.9901, -13.1928,  -9.3456,\n          -8.0127,  -4.9657, -13.1939, -13.1916,  -6.9069,   3.5621,  -8.0617,\n          -2.3771, -13.1909,  -2.3270,  -4.6222,  -1.9885, -13.1917, -13.1936,\n          -4.3452, -10.9114, -12.6538, -13.1915,  -7.1195,  -8.9729,  -8.9674,\n         -13.1921, -13.1915, -11.6921,  -3.9199,  -4.3428, -12.5517, -12.1468,\n         -13.1910,  -3.1865,  -6.0874,  -3.7799,  -4.0049,  -8.9833, -13.1916,\n          -1.1977,  -7.6689,  -3.7021, -12.7018, -12.9387,  -6.5708,  -8.4083,\n         -13.1914, -13.1910, -11.4106,  -5.3985, -11.0676, -13.1916,  -2.7098,\n          -6.5574,  -1.7382, -13.1921,  -5.6939, -12.8759,  -4.6173, -13.1917,\n          -8.8901,  -4.1564, -12.6961, -12.3744,  -4.2906, -13.1911, -13.1908,\n          -5.4162,  -7.6486,  -6.1061,  -3.7959,  -4.6607, -13.1930,  -9.8820,\n          -6.7774, -13.1925, -13.1915, -11.1292, -13.1922, -10.7199,  -0.4570,\n          -2.5546,  -9.1283,  -3.9227,  -6.5301, -11.3650, -13.1920,  -4.0568,\n         -12.0977,  -5.0663,  -3.5855, -13.1923,  -3.8343, -12.5862, -13.1923,\n          -5.6543,  -3.5486,  -8.1924, -13.1927,  -4.2611,  -6.4149, -13.1916,\n           2.9243,  -5.7344,  -5.5096,  -3.7011,  -4.1449,  -5.3996,  -5.2005,\n          -6.8404, -13.1916, -12.6659,  -9.5363,  -5.6747, -13.1922, -13.1918,\n          -4.6434,  -1.8851,  -4.3589,  -3.4486, -13.1929,  -2.8165,  -8.9971,\n         -13.1925, -13.1910, -13.1919,  -3.9093, -13.1922,  -7.6143,  -7.6591,\n         -13.1917, -13.1915,  -5.9560,  -1.4796, -11.7688,  -1.0149, -12.6281,\n         -13.1918, -13.1925,  -7.8796, -10.4976, -13.1923, -13.1924,  -4.1698,\n         -12.5679,  -4.8186,  -3.9189, -12.7682,  -6.4522,  -5.0264,  -4.1087,\n          -8.4848,  -3.4009,  -7.9360, -13.1922, -12.7806,   0.8509,  -4.0547,\n          -5.7215, -11.8249, -11.7593, -11.2282,  -4.2104, -12.5278,  -8.5369,\n         -13.1916, -13.1917, -13.1927, -13.1913,  -3.5071,  -5.3802, -11.6533,\n         -13.1930, -13.1927,  -7.5581, -13.1913, -13.1932, -12.6634, -11.6185,\n         -13.1932,  -4.7364, -13.1920,  -1.9301,  -1.9711, -13.1920, -13.1914,\n         -13.1926,  -3.8151, -13.1915, -13.1929, -12.7451, -13.1916, -13.1906,\n          -1.5908,  -4.8788,  -4.9589, -11.0387,  -4.2817,  -4.2654, -13.1916,\n         -13.1917,  -8.3755,  -2.2135, -12.5216,  -7.8753,  -5.7151,  -7.3396,\n         -13.1912,  -7.4673,  -6.4932,  -4.7898, -13.1911,  -3.9543,  -7.6126,\n         -13.1920,  -5.3118,  -4.9771,  -6.6276, -13.1926,  -7.6431, -10.1272,\n         -12.8810,  -3.9569, -13.1925,  -5.8830,  -4.0492, -11.8260, -11.9603,\n         -13.1907,  -4.8621,  -2.9338, -10.7911, -12.0277, -11.8962,  -9.5004,\n         -13.1919, -12.6274, -12.7078, -13.1924, -12.5819,  -6.5209, -13.1920,\n          -6.2443,  -7.9317,  -4.1902, -12.8083,  -1.4489, -13.1935, -11.8275,\n         -12.4622,  -6.8773, -13.1919, -11.8884, -11.1579,  -6.3440,  -9.2488,\n         -13.1932, -12.8078,  -3.7724,  -1.6698,  -5.2117, -13.1918,   1.0914,\n         -13.1918,  -8.8628,  -8.5804,  -8.4214,  -5.8849, -13.1916, -13.1910,\n          -3.1955, -13.1927,  -1.3168,  -1.1165,  -5.2693, -11.8985, -13.1919,\n          -1.8901, -13.1919, -13.1929,  -6.4347,  -5.8642,  -3.3471, -13.1924,\n         -13.1913,  -3.5674,  -5.7034, -13.1927,  -9.1087, -13.1913]],\n       device='cuda:0', grad_fn=<AddmmBackward0>)"},"metadata":{}}],"execution_count":25}]}