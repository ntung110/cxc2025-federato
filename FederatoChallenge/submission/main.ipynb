{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.modelling.rnn import recommend_next_action, BERT4Rec\n",
    "\n",
    "EVENT_MODEL_PATH = './models/bert4rec_model.pth'\n",
    "RETENTION_MODEL_PATH = './models/xgb_classifier.pkl'\n",
    "TIME_USAGE_MODEL_PATH = './models/xgb_regressor.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Framework\n",
    "\n",
    "in this notebook, we will showcase our optimization framework for suggesting the next event which yields the highest sucess rate or retaining users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 32)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>device_family_linux_max</th><th>device_family_mac os x_max</th><th>device_family_windows_max</th><th>region_grouped_international_max</th><th>region_grouped_midwest_max</th><th>region_grouped_northeast_max</th><th>region_grouped_south_max</th><th>region_grouped_west_max</th><th>event_category_account &amp; policy management_max</th><th>event_category_action center &amp; workflow_max</th><th>event_category_dashboard &amp; ui interactions_max</th><th>event_category_other/system events_max</th><th>event_category_session &amp; navigation_max</th><th>event_category_submission &amp; forms_max</th><th>returned_within_28_days_max</th><th>uw_max</th><th>admin_max</th><th>manager_max</th><th>broker_max</th><th>google_max</th><th>microsoft_max</th><th>session_seconds_mean</th><th>client_event_hour_mean</th><th>client_upload_hour_mean</th><th>event_hour_mean</th><th>server_received_hour_mean</th><th>server_upload_hour_mean</th><th>time_to_server_mean</th><th>server_to_process_mean</th><th>processing_time_mean</th><th>slug_encoded_mean</th><th>user_sequence</th></tr><tr><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td><td>i32</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>list[i64]</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>937.0</td><td>20.0</td><td>19.851852</td><td>20.0</td><td>19.851852</td><td>19.851852</td><td>1076.148148</td><td>0.0</td><td>3.592593</td><td>0.044815</td><td>[1, 2]</td></tr><tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>14.0</td><td>14.5</td><td>14.0</td><td>14.5</td><td>14.5</td><td>1598.75</td><td>0.0</td><td>1.5</td><td>0.045</td><td>[3, 4, 5]</td></tr><tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>16.0</td><td>20.0</td><td>20.0</td><td>20.0</td><td>20.0</td><td>20.0</td><td>2.0</td><td>0.0</td><td>0.6</td><td>0.0</td><td>[6]</td></tr><tr><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>16.0</td><td>16.0</td><td>16.0</td><td>16.0</td><td>16.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>[7, 9]</td></tr><tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>6.0</td><td>16.0</td><td>17.0</td><td>16.0</td><td>17.0</td><td>17.0</td><td>1.4778e7</td><td>0.0</td><td>10.0</td><td>0.0</td><td>[100, 200]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 32)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ device_fa ┆ device_fa ┆ device_fa ┆ region_gr ┆ … ┆ server_to ┆ processin ┆ slug_enco ┆ user_seq │\n",
       "│ mily_linu ┆ mily_mac  ┆ mily_wind ┆ ouped_int ┆   ┆ _process_ ┆ g_time_me ┆ ded_mean  ┆ uence    │\n",
       "│ x_max     ┆ os x_max  ┆ ows_max   ┆ ernationa ┆   ┆ mean      ┆ an        ┆ ---       ┆ ---      │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ l_m…      ┆   ┆ ---       ┆ ---       ┆ f64       ┆ list[i64 │\n",
       "│ u8        ┆ u8        ┆ u8        ┆ ---       ┆   ┆ f64       ┆ f64       ┆           ┆ ]        │\n",
       "│           ┆           ┆           ┆ u8        ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0         ┆ 0         ┆ 1         ┆ 0         ┆ … ┆ 0.0       ┆ 3.592593  ┆ 0.044815  ┆ [1, 2]   │\n",
       "│ 0         ┆ 1         ┆ 0         ┆ 0         ┆ … ┆ 0.0       ┆ 1.5       ┆ 0.045     ┆ [3, 4,   │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 5]       │\n",
       "│ 0         ┆ 0         ┆ 1         ┆ 0         ┆ … ┆ 0.0       ┆ 0.6       ┆ 0.0       ┆ [6]      │\n",
       "│ 0         ┆ 0         ┆ 1         ┆ 0         ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ [7, 9]   │\n",
       "│ 0         ┆ 0         ┆ 1         ┆ 0         ┆ … ┆ 0.0       ┆ 10.0      ┆ 0.0       ┆ [100,    │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 200]     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample data\n",
    "file_path = os.path.expanduser('~/Desktop/data/preprocessed_data.parquet')\n",
    "df = pl.scan_parquet(file_path).limit(5)\n",
    "df = df.collect()\n",
    "df = df.with_columns(pl.Series('user_sequence', [[1,2], [3,4,5], [6], [7,9], [100, 200]]))\n",
    "df = df.drop('session_id', 'user_id_first')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Event Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize event predictor class\n",
    "class EventPredictor:\n",
    "\n",
    "    def __init__(self, event_model, retention_model, time_usage_model, device):\n",
    "\n",
    "        # Save path\n",
    "        self.event_model = event_model\n",
    "        self.retention_model = retention_model\n",
    "        self.time_usage_model = time_usage_model\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def predict(self, df : pl.DataFrame):\n",
    "        \n",
    "        # Get predictions from models\n",
    "        scores = []\n",
    "\n",
    "        for row in df.iter_rows(named = True):\n",
    "            predicted_action, prob = recommend_next_action(self.event_model, row['user_sequence'], 10, self.device)\n",
    "            retention_y_pred_proba = self.retention_model.predict_proba(\n",
    "                                        pl.DataFrame(row).drop('returned_within_28_days_max', 'user_sequence'))[::,1]\n",
    "            time_usage_y_pred = self.time_usage_model.predict(\n",
    "                                        pl.DataFrame(row).drop('session_seconds_mean', 'user_sequence'))\n",
    "            scores.append(max(prob * retention_y_pred_proba * time_usage_y_pred))\n",
    "\n",
    "        # Get next action\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "num_items = 741\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_heads = 2\n",
    "max_seq_len = 10  # Adjusted for longer sequences if needed\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load event model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "event_model = BERT4Rec(num_items, hidden_size, num_layers, num_heads, max_seq_len).to(device)\n",
    "param_dict = torch.load(os.path.expanduser(EVENT_MODEL_PATH), \n",
    "                        weights_only = False, map_location=torch.device('cpu'))\n",
    "event_model.load_state_dict(param_dict)\n",
    "\n",
    "with open(os.path.expanduser(RETENTION_MODEL_PATH), 'rb') as file:\n",
    "    retention_model = pickle.load(file)\n",
    "\n",
    "with open(os.path.expanduser(TIME_USAGE_MODEL_PATH), 'rb') as file:\n",
    "    time_usage_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(4.407903),\n",
       " np.float32(4.8511276),\n",
       " np.float32(8.221094),\n",
       " np.float32(0.02035117),\n",
       " np.float32(8.060284)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores for each row\n",
    "event_predictor = EventPredictor(event_model, retention_model, time_usage_model, device)\n",
    "scores = event_predictor.predict(df)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
